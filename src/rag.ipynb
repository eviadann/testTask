{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gigachain - основной инструмент построения пайплайнов с большими языковыми моделями;\n",
    "- faiss-cpu - используем векторное хранилище FAISS для размещения чанков (фрагментов текстов для контекста)и эмбеддингов (векторных представлений) этих чанков;\n",
    "- sentence-transformers - библиотека для локального использования эмбеддинговых моделей с ресурса Hugging Face;\n",
    "- rank_bm25 - библиотека для работы с алгоритмами векторизации BM25 (вариации TF-IDF);\n",
    "- playwright - библиотека для автоматизации браузера, в нашем случае для парсинга списка статей с веб-сайта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выполним сбор статей  \n",
    "В качестве источника знаний используем статьи с научно-популярного сайта N + 1. Возьмем последние статьи по космонавтике.  \n",
    "\n",
    "Используем AsyncChromiumLoader из GigaChain для загрузки страницы. Этот инструмент приходится использовать, потому что выборка статей по направлениям подгружает перечень статей не сразу, а значит получить его обычным запросом requests.get() не получится.  \n",
    "\n",
    "Из-за асинхронной работы AsyncChromiumLoader сделаем сбор статей отдельным скриптом.  \n",
    "\n",
    "В результате выполнения скрипта мы получим отдельный текстовый файл со ссылками на статьи по космической тематике.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile parser.py\n",
    "\n",
    "from langchain_community.document_loaders import AsyncChromiumLoader\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Инициализируем загрузчик\n",
    "loader = AsyncChromiumLoader([\"https://nplus1.ru/search?tags=871\"])\n",
    "html = loader.load()\n",
    "articles = 'n1_climb_4 transition-colors duration-75 hover:text-main inline-block mb-10 sm:mb-5 font-spectral leading-24'\n",
    "with open('page.html', 'w') as f:\n",
    "  f.write(html[0].page_content)\n",
    "soup = BeautifulSoup(html[0].page_content, 'html.parser')\n",
    "links = []\n",
    "with open('links.txt', 'w') as f:\n",
    "  for link in soup.find_all('a', class_=articles):\n",
    "    print(link)\n",
    "    links.append(link['href'])\n",
    "    f.write(link['href']+' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python parser.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откроем файл со ссылками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('links.txt') as f:\n",
    "  sources = f.read()\n",
    "\n",
    "print(sources.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
